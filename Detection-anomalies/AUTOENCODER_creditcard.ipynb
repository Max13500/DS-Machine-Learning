{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5495dcdf",
   "metadata": {},
   "source": [
    "### Chargement du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f206cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub as kh\n",
    "import pandas as pd\n",
    "\n",
    "# Télécharger le dataset dans un dossier local\n",
    "dataset_ref = \"jacklizhi/creditcard\"\n",
    "path = kh.dataset_download(dataset_ref)\n",
    "\n",
    "# Localiser le fichier CSV dans le dossier téléchargé\n",
    "csv_file = f\"{path}/creditcard.csv\"\n",
    "\n",
    "# Charger le fichier CSV dans un DataFrame\n",
    "df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a5e46d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    0.998273\n",
       "1    0.001727\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d062679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8ca7f91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476f7d47",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "391a644f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       " 1    0.998273\n",
       "-1    0.001727\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inliers = 1, outliers = -1\n",
    "df['Class'] = df['Class'].replace(1,-1)\n",
    "df['Class'] = df['Class'].replace(0,1)\n",
    "\n",
    "df['Class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9103b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Time',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00455873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation train/test\n",
    "X = df.drop('Class',axis=1)\n",
    "y = df['Class']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a133c8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On sélectionne uniquement les labels qui correspondent aux INLIERS\n",
    "y_train_inliers = y_train[y_train.values==1]\n",
    "\n",
    "# On récupère les variables explicatives de ces index\n",
    "liste = list(y_train_inliers.index.values)\n",
    "X_train_inliers = X_train.loc[liste]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa93bba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALISATION des données\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "X_train_inliers = scaler.fit_transform(X_train_inliers)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2353976c",
   "metadata": {},
   "source": [
    "### Entraînement non supervisé (sur inliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74eb0666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Définition de l'auto-encoder\n",
    "input_dim = X_train_inliers.shape[1]\n",
    "\n",
    "inputs = layers.Input(shape=(input_dim,))\n",
    "encoded = layers.Dense(16, activation=\"relu\")(inputs)\n",
    "encoded = layers.Dense(8, activation=\"relu\")(encoded)\n",
    "\n",
    "decoded = layers.Dense(16, activation=\"relu\")(encoded)\n",
    "decoded = layers.Dense(input_dim, activation=\"tanh\")(decoded) # sortie entre -1 et 1\n",
    "\n",
    "autoencoder = models.Model(inputs, decoded)\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25665f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0120 - val_loss: 0.0049\n",
      "Epoch 2/20\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 3/20\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 4/20\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 5/20\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 6/20\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 7/20\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 8/20\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 9/20\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 10/20\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 11/20\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 12/20\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 13/20\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 14/20\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 15/20\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 16/20\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 17/20\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 18/20\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 19/20\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 20/20\n",
      "\u001b[1m1600/1600\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - loss: 0.0022 - val_loss: 0.0022\n"
     ]
    }
   ],
   "source": [
    "# Entraînement\n",
    "history = autoencoder.fit(\n",
    "    X_train_inliers, X_train_inliers,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    shuffle=True,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f61025a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1781/1781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 766us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Prédit</th>\n",
       "      <th>-1</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Réel</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>83</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2766</td>\n",
       "      <td>54098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Prédit    -1      1\n",
       "Réel               \n",
       "-1        83     15\n",
       " 1      2766  54098"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Évaluation sur le test set\n",
    "reconstructions = autoencoder.predict(X_test)\n",
    "errors = np.mean(np.square(reconstructions - X_test), axis=1)\n",
    "\n",
    "# 5. Définition d’un seuil (ici 95e percentile)\n",
    "threshold = np.percentile(errors, 95)\n",
    "y_pred = (errors > threshold).astype(int)\n",
    "y_pred[y_pred==1]=-1\n",
    "y_pred[y_pred==0]=1\n",
    "\n",
    "# Matrice de confusion\n",
    "pd.crosstab(y_test,y_pred,rownames=['Réel'],colnames=[\"Prédit\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bec5fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.03      0.85      0.06        98\n",
      "           1       1.00      0.95      0.97     56864\n",
      "\n",
      "    accuracy                           0.95     56962\n",
      "   macro avg       0.51      0.90      0.52     56962\n",
      "weighted avg       1.00      0.95      0.97     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "314c0688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC Score: 0.8991482003606168\n",
      "##################################################\n",
      "MCC Score: 0.15177452474022185\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred))\n",
    "print(\"#\"*50)\n",
    "print(\"MCC Score:\", matthews_corrcoef(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
